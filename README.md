ğŸ’³ AI-Driven Credit Risk Assessment System (Explainable AI)

An AI-driven, explainable credit risk assessment system designed to support transparent and responsible credit decision-making.
The system predicts the probability of customer default, categorizes risk into Low / Medium / High tiers, and provides human-readable explanations to assist decision-makers.

âš ï¸ This is a decision-support system, not an automated approval engine.

ğŸ“Œ Key Features

End-to-end Machine Learning pipeline

Probability-based credit default prediction

Risk tiers (Low / Medium / High) aligned with industry practice

Explainable AI (XAI) for transparent decisions

Input validation and out-of-distribution safety handling

Professional Streamlit dashboard

Offline SHAP analysis for model interpretability

ğŸ§  Why This Project Matters

In real banking and fintech systems:

Models must be interpretable

Decisions must be explainable

Humans must remain in the loop

This project reflects how credit risk models are actually used in production, not just how they are trained.

ğŸ“Š Dataset

UCI Credit Card Default Dataset (Taiwan)
A real-world financial dataset widely used in academic research and industry benchmarking.

Target Variable

default.payment.next.month â†’ Indicates whether the customer defaulted

Example Features

LIMIT_BAL â€“ Credit limit

AGE, SEX â€“ Demographics

PAY_0 â€¦ PAY_6 â€“ Repayment status

BILL_AMT* â€“ Outstanding bills

PAY_AMT* â€“ Payments made

ğŸ—ï¸ System Architecture
User Input (UI)
      â†“
Input Validation & Safety Capping
      â†“
Feature Engineering
      â†“
Scaling (StandardScaler)
      â†“
ML Model (Logistic Regression)
      â†“
Probability of Default
      â†“
Risk Tier (Low / Medium / High)
      â†“
Human-Readable Explanation
      â†“
Decision Recommendation

âš™ï¸ Tech Stack

Language: Python

ML: Scikit-learn (Logistic Regression)

Data: Pandas, NumPy

Explainability: SHAP (offline analysis)

UI: Streamlit

Model Persistence: Joblib


ğŸš€ How to Run the Project
1ï¸âƒ£ Clone the Repository
git clone https://github.com/<ravikiranediga>/credit-risk-xai.git
cd credit-risk-xai

2ï¸âƒ£ Create Virtual Environment
python -m venv venv


Activate:

Windows

venv\Scripts\activate


Mac / Linux

source venv/bin/activate

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Run the Pipeline
python src/data_processing.py
python src/train_models.py
python src/explainability.py

5ï¸âƒ£ Launch the Application
streamlit run app/main.py

ğŸ§  Explainable AI (XAI)

Explainability is handled at two levels:

User-level (UI):
Business-friendly explanations such as repayment behavior and credit exposure.

Model-level (Offline):
SHAP visualizations saved in the outputs/ directory for audit and analysis.

This ensures both usability and model transparency.

ğŸ“ˆ Risk Interpretation
Probability of Default	Risk Level
< 30%	Low Risk
30â€“60%	Medium Risk
> 60%	High Risk
ğŸ”’ Disclaimer

This system provides decision support only.
Final credit approval decisions must always involve human judgment and institutional policy checks.

ğŸ‘¤ Author & Contact

Name: Ravi Kiran Ediga
Role: Aspiring Data Scientist / Machine Learning Engineer

GitHub: https://github.com/ravikiranediga

LinkedIn: https://www.linkedin.com/in/ravikiranediga

â­ Final Note


This project demonstrates end-to-end ownership, explainable AI, and real-world ML deployment thinking, making it suitable as a major project for interviews and professional portfolios.
